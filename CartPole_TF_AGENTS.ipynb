{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF Agents\n",
    "\n",
    "# Packages: pip install tf-nightly tf-agents-nightly pillow matplotlib gym\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import PIL\n",
    "import os\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tf_agents.agents.dqn import dqn_agent\n",
    "from tf_agents.agents.dqn import q_network\n",
    "from tf_agents.drivers import dynamic_step_driver\n",
    "from tf_agents.environments import suite_gym\n",
    "from tf_agents.environments import gym_wrapper\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.environments import trajectory\n",
    "from tf_agents.metrics import metric_utils\n",
    "from tf_agents.metrics import tf_metrics\n",
    "from tf_agents.policies import random_tf_policy\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "from tf_agents.utils import common\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from IPython.display import HTML\n",
    "from IPython.display import Image\n",
    "from IPython.display import display\n",
    "\n",
    "# Hyperparameters \n",
    "num_iterations = 5000\n",
    "initial_collect_steps = 1000\n",
    "collect_steps_per_iteration = 1 \n",
    "replay_buffer_capacity = 100000\n",
    "fc_layer_params = (100,)\n",
    "batch_size = 64\n",
    "learning_rate = 1e-3\n",
    "log_interval = 200  \n",
    "num_eval_episodes = 10\n",
    "eval_interval = 1000\n",
    "\n",
    "# !!!!!!!!!!!!!!!!!!\n",
    "tf.compat.v1.enable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "\n",
    "def create_gif(env):\n",
    "    gif = []\n",
    "    for i in range(200):\n",
    "        gif.append(PIL.Image.fromarray(env.render(mode='rgb_array')))\n",
    "        env.step(env.action_space.sample())\n",
    "\n",
    "    filename = str(time.time()) +'.gif'\n",
    "    print(filename)\n",
    "    gif[0].save(filename, format='GIF', append_images=gif[1:], save_all=True, duration=90, loop=0)\n",
    "    display(Image(url=filename))\n",
    "\n",
    "    time.sleep(0.1) # To display the file BEFORE it removes it\n",
    "    os.remove(filename)\n",
    "    \n",
    "def compute_avg_return(environment, policy, num_episodes=10):\n",
    "  total_return = 0.0\n",
    "  for _ in range(num_episodes):\n",
    "\n",
    "    time_step = environment.reset()\n",
    "    episode_return = 0.0\n",
    "\n",
    "    while not time_step.is_last():\n",
    "      action_step = policy.action(time_step)\n",
    "      time_step = environment.step(action_step.action)\n",
    "      episode_return += time_step.reward\n",
    "    total_return += episode_return\n",
    "\n",
    "  avg_return = total_return / num_episodes\n",
    "  return avg_return.numpy()[0]\n",
    "\n",
    "def collect_step(environment, policy):\n",
    "  time_step = environment.current_time_step()\n",
    "  action_step = policy.action(time_step)\n",
    "  next_time_step = environment.step(action_step.action)\n",
    "  traj = trajectory.from_transition(time_step, action_step, next_time_step)\n",
    "\n",
    "  replay_buffer.add_batch(traj) # Add trajectory to the replay buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1554715686.4494634.gif\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"1554715686.4494634.gif\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ENV init \n",
    "tf_env = suite_gym.load('CartPole-v0')\n",
    "tf_env.reset()\n",
    "\n",
    "train_env = tf_py_environment.TFPyEnvironment(tf_env)\n",
    "eval_env = tf_py_environment.TFPyEnvironment(tf_env)\n",
    "\n",
    "create_gif(tf_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent (DQN)\n",
    "q_net = q_network.QNetwork(\n",
    "    train_env.observation_spec(),\n",
    "    train_env.action_spec(),\n",
    "    fc_layer_params=fc_layer_params)\n",
    "\n",
    "optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "\n",
    "train_step_counter = tf.compat.v2.Variable(0)\n",
    "\n",
    "tf_agent = dqn_agent.DqnAgent(\n",
    "    train_env.time_step_spec(),\n",
    "    train_env.action_spec(),\n",
    "    q_network=q_net,\n",
    "    optimizer=optimizer,\n",
    "    td_errors_loss_fn=dqn_agent.element_wise_squared_loss,\n",
    "    train_step_counter=train_step_counter)\n",
    "tf_agent.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0405 11:10:31.347745 140453646894912 backprop.py:818] The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.int64\n",
      "W0405 11:10:31.355251 140453646894912 backprop.py:818] The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.int64\n",
      "W0405 11:10:31.362432 140453646894912 backprop.py:818] The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.int64\n",
      "W0405 11:10:31.371007 140453646894912 backprop.py:818] The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.int64\n",
      "W0405 11:10:31.377259 140453646894912 backprop.py:818] The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.int64\n"
     ]
    }
   ],
   "source": [
    "# Policy\n",
    "eval_policy = tf_agent.policy\n",
    "collect_policy = tf_agent.collect_policy\n",
    "\n",
    "random_policy = random_tf_policy.RandomTFPolicy(train_env.time_step_spec(),\n",
    "                                                train_env.action_spec())\n",
    "\n",
    "compute_avg_return(eval_env, random_policy, num_eval_episodes)\n",
    "\n",
    "replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n",
    "    data_spec=tf_agent.collect_data_spec,\n",
    "    batch_size=train_env.batch_size,\n",
    "    max_length=replay_buffer_capacity)\n",
    "\n",
    "for _ in range(initial_collect_steps):\n",
    "  collect_step(train_env, random_policy)\n",
    "\n",
    "dataset = replay_buffer.as_dataset(\n",
    "    num_parallel_calls=3, sample_batch_size=batch_size, num_steps=2).prefetch(3)\n",
    "\n",
    "iterator = iter(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 200: loss = 13.24293327331543\n",
      "step = 400: loss = 28.239105224609375\n",
      "step = 600: loss = 45.36333465576172\n",
      "step = 800: loss = 28.141746520996094\n",
      "step = 1000: loss = 41.08706283569336\n",
      "step = 1000: Average Return = 23.700000762939453\n",
      "step = 1200: loss = 32.47084045410156\n",
      "step = 1400: loss = 22.452899932861328\n",
      "step = 1600: loss = 29.250328063964844\n",
      "step = 1800: loss = 20.4435977935791\n",
      "step = 2000: loss = 34.661781311035156\n",
      "step = 2000: Average Return = 66.30000305175781\n",
      "step = 2200: loss = 59.59206008911133\n",
      "step = 2400: loss = 75.27734375\n",
      "step = 2600: loss = 54.35028076171875\n",
      "step = 2800: loss = 73.85121154785156\n",
      "step = 3000: loss = 52.80146026611328\n",
      "step = 3000: Average Return = 77.69999694824219\n",
      "step = 3200: loss = 126.77091979980469\n",
      "step = 3400: loss = 19.332561492919922\n",
      "step = 3600: loss = 96.30709838867188\n",
      "step = 3800: loss = 105.86681365966797\n",
      "step = 4000: loss = 82.61153411865234\n",
      "step = 4000: Average Return = 58.0\n",
      "step = 4200: loss = 112.8319091796875\n",
      "step = 4400: loss = 106.68423461914062\n",
      "step = 4600: loss = 44.203392028808594\n",
      "step = 4800: loss = 21.823884963989258\n",
      "step = 5000: loss = 135.94552612304688\n",
      "step = 5000: Average Return = 56.79999923706055\n",
      "1554455518.814952.gif\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"1554455518.814952.gif\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAH1FJREFUeJzt3Xt8XVWd9/HPL2maliZNb0lIm5ZSmibcSlti5Sa0oty8FJ9BBREZRauPzAw84zNaUEe8zLzUEVSeURQVxXkJAopSFZGCBRG52GJpm9I2FVqa3pJCm6SlSZuc3/PHXimnZTc5bXOyk5zv+/U6r7P3Onvn/Bak/Xbttc4+5u6IiIgcLC/pAkREpH9SQIiISCwFhIiIxFJAiIhILAWEiIjEUkCIiEisrAWEmU00s8VmtsrM6szsutB+k5ltMrNl4XFJ2jk3mNk6M1tjZhdmqzYREemZZetzEGZWAVS4+3NmVgwsBS4F3gfscvdvHHT8ScDdwGxgPPAIMM3dO7NSoIiIdCtrIwh33+Luz4XtVuAFYEI3p8wDfu7u7e7+ErCOKCxERCQBQ/riTcxsMjATeAY4G/gnM/sQsAT4lLvvIAqPp9NOayAmUMxsPjAfYMSIEafX1NRktXYRkcFm6dKl2929tKfjsh4QZlYE/BK43t1bzOw24MuAh+ebgY9k+vPc/XbgdoDa2lpfsmRJ7xctIjKImdmGTI7L6iomMysgCoefufv9AO6+zd073T0F/IDXLyNtAiamnV4Z2kREJAHZXMVkwI+AF9z9lrT2irTD3gOsDNsLgcvNrNDMjgeqgGezVZ+IiHQvm5eYzgauAlaY2bLQdiNwhZnNILrEtB74OIC715nZvcAqoAO4ViuYRESSk7WAcPc/Axbz0oPdnPMfwH9kqyYREcmcPkktIiKxFBAiIhJLASEiIrEUECIiEksBISIisRQQIiISSwEhIiKxFBAiIhJLASEiIrEUECIiEksBISIisRQQIiISSwEhIiKxFBAiIhJLASEiIrEUECIiEksBISIisRQQIiISSwEhIiKxFBAiIhJLASEiIrEUECIiEksBISIisRQQIiISSwEhIiKxFBAiIhJLASEiIrEUECIiEksBISIisRQQIiISSwEhIiKxFBAiIhJLASEiIrEUECIiEksBISIisRQQIiISK2sBYWYTzWyxma0yszozuy60jzGzRWZWH55Hh3Yzs1vNbJ2ZLTezWdmqTUREepbNEUQH8Cl3Pwk4A7jWzE4CFgCPunsV8GjYB7gYqAqP+cBtWaxNRER6kLWAcPct7v5c2G4FXgAmAPOAO8NhdwKXhu15wE898jQwyswqslWfiIh0r0/mIMxsMjATeAYod/ct4aWtQHnYngBsTDutIbQd/LPmm9kSM1vS1NSUtZpFRHJd1gPCzIqAXwLXu3tL+mvu7oAfzs9z99vdvdbda0tLS3uxUhERSZfVgDCzAqJw+Jm73x+at3VdOgrPjaF9EzAx7fTK0CYiIgnI5iomA34EvODut6S9tBC4OmxfDTyQ1v6hsJrpDKA57VKUiIj0sSFZ/NlnA1cBK8xsWWi7EfgqcK+ZXQNsAN4XXnsQuARYB7wGfDiLtYmISA+yFhDu/mfADvHy+THHO3BttuoREZHDo09Si4hILAWEiIjEUkCIiEgsBYSIiMRSQIiISCwFhIiIxFJAiIhILAWEiIjEUkCIiEgsBYSIiMRSQIiISCwFhIiIxFJAiIhILAWEiIjEUkCIiEgsBYSIiMRSQIiISCwFhIiIxFJAiIhILAWEiIjEUkCIiEisIT0dYGalwMeAyenHu/tHsleWiIgkrceAAB4AngAeATqzW46IiPQXmQTEMe7+maxXIiIi/UomcxC/NbNLsl6JiIj0K5kExHVEIbHHzFrMrNXMWrJdmIiIJKvbS0xmZsDJ7v5yH9UjIiL9RLcjCHd34Hd9VIuIiPQjmVxies7M3pT1SkREpF/JZBXTm4ErzWwDsBswosHF9KxWJiIiicokIC7MehUiItLvZBIQnvUqRESk38kkIH5HFBIGDAOOB9YAJ2exLhERSViPAeHup6bvm9ks4JNZq0hERPqFw76bq7s/RzRxLSIig1gmd3P917TdPGAWsDmD8+4A3gk0uvspoe0mojvDNoXDbnT3B8NrNwDXEN0Q8F/c/Q+Zd0NERHpbJiOI4rRHIdGcxLwMzvsJcFFM+zfdfUZ4dIXDScDlRPMaFwHfNbP8DN5DRESyJJNJ6lXufl96g5m9F7jvEMcD4O5/MrPJGdYxD/i5u7cDL5nZOmA28FSG54uISC/LZARxQ4ZtmfonM1tuZneY2ejQNgHYmHZMQ2gTEZGEHHIEYWYXA5cAE8zs1rSXRgIdR/h+twFfJlo2+2XgZuCwvpnOzOYD8wEmTZp0hGWIiEhPuhtBbAaWAG3A0rTHQo7w09Xuvs3dO909BfyA6DISwCZgYtqhlaEt7mfc7u617l5bWlp6JGWIiEgGDjmCcPfngefN7K5w3CR3X3M0b2ZmFe6+Jey+B1gZthcCd5nZLcB4oAp49mjeS0REjk4mk9QXAd8AhgLHm9kM4Evu/u7uTjKzu4E5wDgzawC+AMwJ5zuwHvg4gLvXmdm9wCqiy1fXuru+/1pEJEEWfeVDNweYLQXeCjzm7jND24qDP2GdhNraWl+yZEnSZYiIDChmttTda3s6LpNVTPvcvfmgNt3AT0RkkMvkElOdmX0AyDezKuBfgL9ktywREUlaJiOIfyb6hHM7cBfQAlyfzaJERCR5mdzN9TXgs+EBgJlNAl7OYl0iIpKwbkcQZnammV1mZmVhf3pY9vpkn1QnIiKJOWRAmNl/AXcA/wD8zsy+AjwMPEP0OQURERnEurvE9A5gpru3hXsmbQROcff1fVKZiIgkqrtLTG3u3gbg7juAeoWDiEju6G4EMcXMFqbtH5++39MnqUVEZGDrLiAO/lKgm7NZiIiI9C/d3azv8b4sRERE+pdMPignIiI5SAEhIiKxMg4IMzsmm4WIiEj/0mNAmNlZZrYKWB32TzOz72a9MhERSVQmI4hvEn3F6Cuw/5vmzs1mUSIikryMLjG5+8aDmvRtbyIig1wm3wex0czOAtzMCoDrgBeyW5aIiCQtkxHEJ4BrgQnAJmBG2BcRkUEsk++D2A5c2Qe1iIhIP9JjQJjZrTHNzcASd3+g90sSEZH+IJNLTMOILivVh8d0oBK4xsy+lcXaREQkQZlMUk8Hznb3TgAzuw14AjgHWJHF2kREJEGZjCBGA0Vp+yOAMSEw2rNSlYiIJC6TEcTXgWVm9hhgRB+S+08zGwE8ksXaREQkQZmsYvqRmT0IzA5NN7r75rD9b1mrTEREEpXpzfragC3ADmCqmelWGyIig1wmy1w/SvTp6UpgGXAG8BTw1uyWJiIiScpkBHEd8CZgg7vPBWYCO7NalYiIJC6TgGhz9zYAMyt099VAdXbLEhGRpGWyiqnBzEYBvwYWmdkOYEN2yxIRkaRlsorpPWHzJjNbDJQAD2W1KhERSVy3AWFm+UCdu9cAuPvjfVKViIgkrts5iPBp6TVmNqmP6hERkX4ikzmI0UCdmT0L7O5qdPd3Z60qERFJXCYB8fmsVyEiIv1Oj8tcw7zDeqAgbP8VeK6n88zsDjNrNLOVaW1jzGyRmdWH59Gh3czsVjNbZ2bLzWzWEfdIRER6RY8BYWYfA34BfD80TSBa8tqTnwAXHdS2AHjU3auAR8M+wMVAVXjMB27L4OeLiEgWZfJBuWuBs4EWAHevB8p6Osnd/wS8elDzPODOsH0ncGla+0898jQwyswqMqhNRESyJJOAaHf3vV07ZjYE8CN8v3J33xK2twLlYXsCsDHtuIbQ9gZmNt/MlpjZkqampiMsQ0REepJJQDxuZjcCw83s7cB9wG+O9o3d3TmCoHH329291t1rS0tLj7YMERE5hEwCYgHQRPT1oh8HHgQ+d4Tvt63r0lF4bgztm4CJacdVhjYREUlIJgFxKdH8wHvd/TJ3/0H41/+RWAhcHbavBh5Ia/9QWM10BtCcdilKREQSkElAvAtYa2b/Y2bvDHMQPTKzu4m+N6LazBrM7Brgq8DbzaweeFvYh2hU8iKwDvgB8MnD7IeIiPSyTG7W92EzKyBainoF8B0zW+TuH+3hvCsO8dL5Mcc60WopERHpJzIaDbj7PjP7PdGk8nCiy07dBoSIiAxsmXxQ7mIz+wlQD/wD8EPg2CzXJSIiCctkBPEh4B7g4+7enuV6RESkn8hkDuKAuQQzOwe4wt01ZyAiMohluiJpJvAB4L3AS8D92SxKRESSd8iAMLNpRKuWrgC2E11mMnef20e1iYhIgrobQawGngDe6e7rAMzs//RJVSIikrjuVjH9L2ALsNjMfmBm5wPWN2WJiEjSDhkQ7v5rd78cqAEWA9cDZWZ2m5ld0FcFiohIMjL5Rrnd7n6Xu7+L6CZ6fwM+k/XKREQkUZnci2k/d98Rbrf9httliIjI4HJYASEiIrlDASEiIrEy+qCciPRPnSnn5VdfY+22VtY17mLttlYKh+Rx3rQyzqkaR8nwgqRLlAFMASEyAHQFQf22VupDEKzdtou/N+1ib0dq/3ETRg1nV3sH9y5pID/POP240cytLmNuTSnV5cWYaaW6ZE4BIdKPdKacjWFEUN+4i/q0IGg/KAimlhVxztSxVJUXM628mKllRRQVDqGjM8WyjTtZvKaRxaub+NpDq/naQ6upKBnGnOpS5lSXcfbUcRQV6o+/dM+O/NtDk1dbW+tLlixJugyRw9YVBF2jgUMFwfiSYSEAiqgqK6aqvIiq8uLD+st9a3Mbj69t5LE1TTxRv51d7R0U5Buzjx/D3Ooy5lSXcULpCI0ucoiZLXX32h6PU0CIZE9nymnY8Rprt+06YJ5gXeMbg2BqeTHTyoqYVh4FwdSyIoqH9e4cwt6OFEs37OCxNY0sXtPI2m27AJg4Znh0Kaq6jDOmjGX40PxefV/pXxQQIn0olXI2hiCob2ylPgTC35t20bbv9SCo6BoRlBXtHw1UZSEIMtWw4zUeW9PEY2saeXLdK+zZ10nhkDzOmDKWudWlzK0p47ixIxKpTbJHASGSBamU07BjTzRJHIKgvjEaERwcBFPDaGBaCIKpZUWMTCgIMtG2r5O/rn+VxaujwHhx+24ApowbwZww0T37+DEUDtHoYqBTQIgchfQg2D9ZHBMEx44cRlV5uCxUFkYE5f07CDK1fvvucCmqiadefIW9HSmGF+Rz9tSxzKkuY051KZWjj0m6TDkCCgiRDKRSzqade/YvG+1aRrqucRd79nXuP64rCKrKDhwR5MrnDPbs7eSpF7fz2Jom/ri6kYYdewCYVl60f6K7dvJoCvL12duBQAEhkiY9CF5fOfTGICgfWRhGA8VhZFDE1LLinAmCTLg7f2/avX+i+9mXXmVfp1NUOIRzpo5jbk20lLZ85LCkS5VDUEBIzvvT2iZ+vWwT68KI4LW9BwbB6yEQjQqmlhZTcoyC4HDtau/gyXXbo8BY3cTWljYATqoYydyaUuZWlzFj4iiGaHTRbyggJGc1trTxpd+u4rfLtzBmxFBOqhh54IRxmYIgW9ydNdtaWby6icVrGlm6YQedKadkeAHnTitlbnUp504rZVxRYdKl5jQFhOScVMq569mX+dpDq2nvSHHtnKl8Ys4UrbpJUPOeffy5fjuL10Qf1Nu+qx0zmD6hJKyMKmP6hBLy8vQhvb6kgJCcsnprCzfcv4K/vbyTs04Yy1cuPYUppUVJlyVpUimnbnNLCItG/rZxJ+4wdsRQzptWypyaMs6tGseoY4YmXeqgp4CQnPDa3g6+/Wg9P3ziJUqGF/C5d5zIe2ZO0G0jBoBXd+/lifomFq9u5PG1Tex4bR95BjMnjWZuuGfUyeNH6v9lFiggZNBbvKaRz/96JQ079vD+2oksuLiG0SP0r8+BqDPlPN+wc/+nupc3NANQVlzInOpoovvsqnGD4vMl/YECQgatbS1tfOk3q/jdii2cUDqC/3zPqbx5ytiky5Je1NTazuNro4nuP61torWtgyF5Ru3k0dHcRXUZ08qLNLo4QgoIGXQ6U85dz2zg6w+tob0zxT/Pncr88zQJPdh1dKZ47uWu25c3snprKxDd4HBOTRQWJ5SOoCA/j/w8Y0i+MSQvLzyH7TzTRHgaBYQMKqs2t3Djr1awbONOzpk6ji9fegrHj9NN5HLRluY9PL4mGl38uX47u9M+39KdPGN/cOTn2f5AKcgz8vONgryugIkC5YCACdv5eXkUHHx+2O8Kojec37V/wGtvfI/0GuLfI/2cPEYU5nPM0CP7To9MA0LfGCL92mt7O/jWI/X86M8vMWp4Ad96/wzmzRivSws5rKJkOJfPnsTlsyextyPFkg2v0tjSzr7OFJ0pZ1/K6exM0ZHy6NG13XnQfioc3+nhOX0//ZwUbR0Hnh+9T4rOzvB+aed3nZPK8r+9P3HeCSy4uCar76GAkH7rj6u38flf17Fp5x6umD2Rz1xUoyWQcoChQ/I464RxSZcRK9UVUAeFTUdsIIXAeUPQHBho+9tSzkkVI7PeBwWE9DvbWtr44m/qeHDFVqrKirjvE2fypsljki5L5LDk5RlD84yhDNxbjCggpN/oTDk/C5PQ+zpT/NuF1XzsLVMYOmTg/gETGcgSCQgzWw+0Ap1Ah7vXmtkY4B5gMrAeeJ+770iiPul7dZubufH+FTzf0Mxbqsbx5XmnMFmT0CKJSnIEMdfdt6ftLwAedfevmtmCsP+ZZEqTvrK7vYNvPbKWO55cz+hjCvj25TN492mahBbpD/rTJaZ5wJywfSfwGAqIQe2RVdv49wdWsrm5jStmT2LBRTW6y6pIP5JUQDjwsJk58H13vx0od/ct4fWtQHnciWY2H5gPMGnSpL6oVXrZ1uY2blpYx0N1W5lWXsQvrjiTWk1Ci/Q7SQXEOe6+yczKgEVmtjr9RXf3EB5vEMLkdog+KJf9UqW3dKac/3lqPd94eC37OlN8+qJqPnqOJqFF+qtEAsLdN4XnRjP7FTAb2GZmFe6+xcwqgMYkapPsWLmpmRt/tYLlDc2cO62Ur8w7hUlj9YX3Iv1ZnweEmY0A8ty9NWxfAHwJWAhcDXw1PD/Q17VJ79vd3sEti9by4ydfYsyIQm69Yibvml6hSWiRASCJEUQ58KvwF8QQ4C53f8jM/grca2bXABuA9yVQm/Sih+u2ctPCOjY3t3Hlmyfx6YtqKBmuSWiRgaLPA8LdXwROi2l/BTi/r+uR3rd55x5uWljHw6u2UV1ezC8/MJPTj9MktMhA05+WucoA15ly7vzLem5+eA2d7iy4uIZrzjmegnxNQosMRAoI6RUrGqJJ6BWbmjlvWilfufQUJo7RJLTIQKaAkKOyq72Dmx9ew51/Wc/YokL++wMzecepmoQWGQwUEHLE/hAmobe2tPHBNx/H/72wWpPQIoOIAkIO26ade/jCA3U88sI2ao4t5jtXzmLWpNFJlyUivUwBIRnr6Ezxk7+s55ZFa3GHGy6u4SOahBYZtBQQkpHlDTu54f4V1G1uYW51KV+ap0lokcFOASHdam3bx80Pr+WnT61nXFEh371yFhefcqwmoUVygAJCYrk7f6jbyhcW1tHY2s5VZ0ST0COHaRJaJFcoIOQNoknolTzyQiMnVozk+1fVMmPiqKTLEpE+poCQ/To6U/z4yfV885FoEvqzl5zIh8+ezBBNQovkJAWEALBs405uvH8Fq7a0cH5NGV+cdzKVozUJLZLLFBA5rqVtHzf/YQ0/fXoDZcWFfO+Ds7jwZE1Ci4gCIme5O79fuZUv/iaahL76zMl86oJpFGsSWkQCBUQO2vjqa3xhYR1/XN3IyeNHcvtVtZymSWgROYgCIofs60zx4ydf4puL6jGDz73jRP7xLE1Ci0g8BcQg197RyQtbWlnesJO7n93IC1taeNuJZXxx3ilMGDU86fJEpB9TQAwiHZ0p6ht3sbxhJ883NLOioZnVW1vY1+kAVI4ezvc+eDoXnlyuSWgR6ZECYoBKpZz1r+xmxaZmnt/YzPKGndRtbmHPvk4AiocNYXplCR99yxSmTyhh+sRRjC8ZpmAQkYwpIAYAd2dLc9v+kcHyhp0sb2imta0DgGEFeZw8voTLZ0/ktMpRTK8sYfLYEeTlKQxE5MgpIPqhV3a1s7yhOTyiUNi+qx2AIXlGTUUx7zptPKdVljC9chRVZUWaaBaRXqeASFhr2z5WbEoLg43NbNq5BwAzOKG0iHOnjds/MjixYiTDCvITrlpEcoECog+17eukbnPL/ktEyxt28uL23Xg0h8zEMcOZMWkUV591HNMrR3HKhBKKCvW/SESSob99smRfZ4q121oPGBms3dZKRypKg7LiQqZXjmLejAlMD5eKxowYmnDVIiKvU0D0glTKeXH77gNGBnWbW2jvSAFQMryA6ZUlfLxmCtMrR3Fa5SiOLRmWcNUiIt1TQBwmd6dhx55oeWnDTpZvbGblpmZa26MVRcML8jl1QglXnXEcp1aWcFrlKI4be4yWl4rIgKOA6EFTa/sBy0tXNDTzyu69ABTkGydWjGTezPH7RwZTy4rI1/JSERkEFBBpmvfsY0VDM8s3RSOD5Q072dzcBkCeQVVZMW+tKWP6xFFMn1BCTUUxhUO0okhEBqecDYg9ezup29x8wAfPXtq+e//rx409htMnj+EjYQL55PEjGaEVRSKSQ3Lyb7zfPL+Z6+9ZRmdYUXTsyGFMryzhstMrmV5ZwqkTShh1jFYUiUhuy8mAOHn8SD4554Qwb1BC2UitKBIROVhOBsSU0iI+dUF10mWIiPRruoGPiIjEMu+6z8MAZGZNwIYjPH0csL0XyxkI1OfcoD7nhqPp83HuXtrTQQM6II6GmS1x99qk6+hL6nNuUJ9zQ1/0WZeYREQklgJCRERi5XJA3J50AQlQn3OD+pwbst7nnJ2DEBGR7uXyCEJERLqhgBARkVg5GRBmdpGZrTGzdWa2IOl6joaZ3WFmjWa2Mq1tjJktMrP68Dw6tJuZ3Rr6vdzMZqWdc3U4vt7Mrk6iL5kws4lmttjMVplZnZldF9oHc5+HmdmzZvZ86PMXQ/vxZvZM6Ns9ZjY0tBeG/XXh9clpP+uG0L7GzC5MpkeZM7N8M/ubmf027A/qPpvZejNbYWbLzGxJaEvud9vdc+oB5AN/B6YAQ4HngZOSruso+nMuMAtYmdb2dWBB2F4AfC1sXwL8HjDgDOCZ0D4GeDE8jw7bo5Pu2yH6WwHMCtvFwFrgpEHeZwOKwnYB8Ezoy73A5aH9e8D/DtufBL4Xti8H7gnbJ4Xf90Lg+PDnID/p/vXQ938F7gJ+G/YHdZ+B9cC4g9oS+93OxRHEbGCdu7/o7nuBnwPzEq7piLn7n4BXD2qeB9wZtu8ELk1r/6lHngZGmVkFcCGwyN1fdfcdwCLgouxXf/jcfYu7Pxe2W4EXgAkM7j67u+8KuwXh4cBbgV+E9oP73PXf4hfA+RZ9peE84Ofu3u7uLwHriP489EtmVgm8A/hh2DcGeZ8PIbHf7VwMiAnAxrT9htA2mJS7+5awvRUoD9uH6vuA/G8SLiPMJPoX9aDuc7jUsgxoJPoD/3dgp7t3hEPS69/ft/B6MzCWAdZn4FvAp4FU2B/L4O+zAw+b2VIzmx/aEvvdzsm7ueYSd3czG3Rrmc2sCPglcL27t1jad34Pxj67eycww8xGAb8CahIuKavM7J1Ao7svNbM5SdfTh85x901mVgYsMrPV6S/29e92Lo4gNgET0/YrQ9tgsi0MNQnPjaH9UH0fUP9NzKyAKBx+5u73h+ZB3ecu7r4TWAycSXRJoesfeen17+9beL0EeIWB1eezgXeb2Xqiy8BvBb7N4O4z7r4pPDcS/UNgNgn+budiQPwVqAqrIYYSTWgtTLim3rYQ6Fq5cDXwQFr7h8LqhzOA5jB0/QNwgZmNDiskLght/U64rvwj4AV3vyXtpcHc59IwcsDMhgNvJ5p7WQxcFg47uM9d/y0uA/7o0ezlQuDysOLneKAKeLZvenF43P0Gd69098lEf0b/6O5XMoj7bGYjzKy4a5vod3IlSf5uJz1rn8SDaPZ/LdF13M8mXc9R9uVuYAuwj+ha4zVE114fBeqBR4Ax4VgDvhP6vQKoTfs5HyGawFsHfDjpfnXT33OIrtMuB5aFxyWDvM/Tgb+FPq8E/j20TyH6y24dcB9QGNqHhf114fUpaT/rs+G/xRrg4qT7lmH/5/D6KqZB2+fQt+fDo67r76Ykf7d1qw0REYmVi5eYREQkAwoIERGJpYAQEZFYCggREYmlgBARkVgKCJHDZGafteiuqsvDXTffbGbXm9kxSdcm0pu0zFXkMJjZmcAtwBx3bzezcUR3Bf4L0Tr07YkWKNKLNIIQOTwVwHZ3bwcIgXAZMB5YbGaLAczsAjN7ysyeM7P7wr2juu73//Vwz/9nzWxqUh0R6YkCQuTwPAxMNLO1ZvZdMzvP3W8FNgNz3X1uGFV8Dnibu88ClhB9r0GXZnc/FfhvojuWivRLupuryGFw911mdjrwFmAucI+98VsJzyD6oponw11mhwJPpb1+d9rzN7NbsciRU0CIHCaPbr39GPCYma3g9RupdTGiL2y54lA/4hDbIv2KLjGJHAYzqzazqrSmGcAGoJXoK1ABngbO7ppfCHfpnJZ2zvvTntNHFiL9ikYQIoenCPh/4fbbHUR3y5wPXAE8ZGabwzzEPwJ3m1lhOO9zRHcQBhhtZsuB9nCeSL+kZa4ifSh8AY6Ww8qAoEtMIiISSyMIERGJpRGEiIjEUkCIiEgsBYSIiMRSQIiISCwFhIiIxPr/VpgBVhP6ILQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training\n",
    "\n",
    "tf_agent.train = common.function(tf_agent.train) # (Optional) Optimize by wrapping some of the code in a graph using TF function.\n",
    "\n",
    "tf_agent.train_step_counter.assign(0) # Reset the train step\n",
    "\n",
    "avg_return = compute_avg_return(eval_env, tf_agent.policy, num_eval_episodes) # Evaluate the agent's policy once before training.\n",
    "returns = [avg_return]\n",
    "\n",
    "for _ in range(num_iterations):\n",
    "\n",
    "  # Collect a few steps using collect_policy and save to the replay buffer.\n",
    "  for _ in range(collect_steps_per_iteration):\n",
    "    collect_step(train_env, tf_agent.collect_policy)\n",
    "\n",
    "  # Sample a batch of data from the buffer and update the agent's network.\n",
    "  experience, unused_info = next(iterator)\n",
    "  train_loss = tf_agent.train(experience)\n",
    "\n",
    "  step = tf_agent.train_step_counter.numpy()\n",
    "\n",
    "  if step % log_interval == 0:\n",
    "    print('step = {0}: loss = {1}'.format(step, train_loss.loss))\n",
    "\n",
    "  if step % eval_interval == 0:\n",
    "    avg_return = compute_avg_return(eval_env, tf_agent.policy, num_eval_episodes)\n",
    "    print('step = {0}: Average Return = {1}'.format(step, avg_return))\n",
    "    returns.append(avg_return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "\n",
    "steps = range(0, num_iterations + 1, eval_interval)\n",
    "plt.plot(steps, returns)\n",
    "plt.ylabel('Average Return')\n",
    "plt.xlabel('Step')\n",
    "plt.ylim(top=250)\n",
    "\n",
    "create_gif(tf_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TFAgents",
   "language": "python",
   "name": "tfagents"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
